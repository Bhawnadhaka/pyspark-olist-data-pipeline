{"cells": [{"cell_type": "markdown", "id": "508068e4-0036-4cbf-956c-a130a685dcbf", "metadata": {"tags": []}, "source": "## Key Considerations for Your Dataproc Cluster\n### 1. Cluster Resources:\n\u2022 **Master: n2-standard-4** :(4 vCPUs, 16 GB RAM, 32GB disk)\n\n\u2022 **Workers (2x)**: n2-standard-4(4 vCPUs, 16 GB RAM, 64GB disk each)\n\n\u2022 **Total**: 8 worker vCPUs, ~32 GB RAM (excluding master node)\n ### 2. Dataproc Features Disabled:\n\u2022 No **autoscaling, Metastore, advanced execution layer, advanced optimizations**\n\n\u2022 **Storage**: pd-balanced (no SSDs, so I/O optimization is crucial)\n\n\u2022 **Networking**: Internal IP enabled\n### 3. Optimization Strategy:\n\u2022 Tune **shuffle partitions, broadcast join threshold**, and **storage persistence**\n\n\u2022 Adjust **parallelism** based on **2 workers x 4 cores**\n\n\u2022 Avoid **excessive caching** due to **disk-based storage**\n"}, {"cell_type": "code", "execution_count": 1, "id": "3e929dc2-7909-4d8d-a3f3-e0d38d5c0097", "metadata": {"tags": []}, "outputs": [], "source": "from pyspark.sql import SparkSession"}, {"cell_type": "code", "execution_count": 1, "id": "18b597df-b4db-4b35-b65e-469700abc069", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "25/04/25 13:00:23 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"}], "source": "spark=SparkSession.builder \\\n.appName('Olist Ecommerce Performance Optimization') \\\n.config('spark.executor.memory','6g') \\\n.config('spark.executor.cores','4') \\\n.config('spark.executor.instance','2') \\\n.config('spark.driver.memory','4g') \\\n.config('spark.driver.maxResultSize','2g') \\\n.config('spark.sql.shuffle.partitions','64') \\\n.config('spark.default.parallelism','64') \\\n.config('spark.sql.adaptive.enabled','true') \\\n.config('spark.sql.adaptive.coalescePartition.enabled','true') \\\n.config('spark.sql.autoBroadcastJoinThreshold',20*1024*1024) \\\n.config('spark.sql.files.maxPartitionBytes','64MB') \\\n.config('spark.sql.files.openCostInBytes','2MB') \\\n.config('spark.memory.fraction',0.8) \\\n.config('spark.memory.storageFraction',0.2) \\\n.getOrCreate()"}, {"cell_type": "code", "execution_count": 2, "id": "c3123455-f4a6-4b65-a3d7-3bcad425d440", "metadata": {"tags": []}, "outputs": [], "source": "hdfs_path='/data/olist/'"}, {"cell_type": "code", "execution_count": 3, "id": "e1d6bc9e-78de-488d-9da4-9b2a04e34e08", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "customers_df = spark.read.csv(hdfs_path + 'olist_customers_dataset.csv',header=True,inferSchema=True)\norders_df = spark.read.csv(hdfs_path + 'olist_orders_dataset.csv',header=True,inferSchema=True)\norder_item_df = spark.read.csv(hdfs_path + 'olist_order_items_dataset.csv',header=True,inferSchema=True)\npayments_df = spark.read.csv(hdfs_path + 'olist_order_payments_dataset.csv',header=True,inferSchema=True)\nreviews_df = spark.read.csv(hdfs_path + 'olist_order_reviews_dataset.csv',header=True,inferSchema=True)\nproducts_df = spark.read.csv(hdfs_path + 'olist_products_dataset.csv',header=True,inferSchema=True)\nsellers_df = spark.read.csv(hdfs_path + 'olist_sellers_dataset.csv',header=True,inferSchema=True)\ngeolocation_df = spark.read.csv(hdfs_path + 'olist_geolocation_dataset.csv',header=True,inferSchema=True)\ncategory_translation_df = spark.read.csv(hdfs_path +'product_category_name_translation.csv',header=True,inferSchema=True)"}, {"cell_type": "code", "execution_count": 4, "id": "f64245d7-c5ab-47bb-83d9-303d9a057008", "metadata": {"tags": []}, "outputs": [], "source": "full_orders_df=spark.read.parquet('/olist/processed/')"}, {"cell_type": "code", "execution_count": 5, "id": "83172dd8-12c6-421a-9967-efa4048b2e37", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- customer_id: string (nullable = true)\n |-- order_id: string (nullable = true)\n |-- seller_id: string (nullable = true)\n |-- product_id: string (nullable = true)\n |-- order_status: string (nullable = true)\n |-- order_purchase_timestamp: timestamp (nullable = true)\n |-- order_approved_at: timestamp (nullable = true)\n |-- order_delivered_carrier_date: timestamp (nullable = true)\n |-- order_delivered_customer_date: timestamp (nullable = true)\n |-- order_estimated_delivery_date: timestamp (nullable = true)\n |-- order_item_id: integer (nullable = true)\n |-- shipping_limit_date: timestamp (nullable = true)\n |-- price: double (nullable = true)\n |-- freight_value: double (nullable = true)\n |-- product_category_name: string (nullable = true)\n |-- product_name_lenght: integer (nullable = true)\n |-- product_description_lenght: integer (nullable = true)\n |-- product_photos_qty: integer (nullable = true)\n |-- product_weight_g: integer (nullable = true)\n |-- product_length_cm: integer (nullable = true)\n |-- product_height_cm: integer (nullable = true)\n |-- product_width_cm: integer (nullable = true)\n |-- seller_zip_code_prefix: integer (nullable = true)\n |-- seller_city: string (nullable = true)\n |-- seller_state: string (nullable = true)\n |-- customer_unique_id: string (nullable = true)\n |-- customer_zip_code_prefix: integer (nullable = true)\n |-- customer_city: string (nullable = true)\n |-- customer_state: string (nullable = true)\n |-- geolocation_zip_code_prefix: integer (nullable = true)\n |-- geolocation_lat: double (nullable = true)\n |-- geolocation_lng: double (nullable = true)\n |-- geolocation_city: string (nullable = true)\n |-- geolocation_state: string (nullable = true)\n |-- review_id: string (nullable = true)\n |-- review_score: string (nullable = true)\n |-- review_comment_title: string (nullable = true)\n |-- review_comment_message: string (nullable = true)\n |-- review_creation_date: string (nullable = true)\n |-- review_answer_timestamp: string (nullable = true)\n |-- payment_sequential: integer (nullable = true)\n |-- payment_type: string (nullable = true)\n |-- payment_installments: integer (nullable = true)\n |-- payment_value: double (nullable = true)\n |-- is_delivered: integer (nullable = true)\n |-- is_canceled: integer (nullable = true)\n |-- order_revenue: double (nullable = true)\n |-- customer_segment: string (nullable = true)\n |-- hour_of_day: integer (nullable = true)\n |-- order_day_type: string (nullable = true)\n\n"}], "source": "full_orders_df.printSchema()"}, {"cell_type": "code", "execution_count": 6, "id": "6ab70d96-4a84-4f0a-875c-46b1951fbb7e", "metadata": {"tags": []}, "outputs": [], "source": "## Optimized Join Strategy"}, {"cell_type": "code", "execution_count": 7, "id": "23e61331-238a-40f2-942d-7e4080b5e20c", "metadata": {"tags": []}, "outputs": [], "source": "## Broadcast"}, {"cell_type": "code", "execution_count": 9, "id": "a655fe64-d787-4872-853a-3b3e27dfc5f3", "metadata": {"tags": []}, "outputs": [], "source": "from pyspark.sql.functions import *\ncustomers_broadcast_df=broadcast(customers_df)\noptimized_broadcast_join=full_orders_df.join(customers_broadcast_df,'customer_id')"}, {"cell_type": "code", "execution_count": 10, "id": "bcdfb286-fa2e-4cdb-8aeb-cc8daf4e0869", "metadata": {"tags": []}, "outputs": [], "source": "## Sort And Merge JOin"}, {"cell_type": "code", "execution_count": 11, "id": "107381ce-53db-41f4-9020-2aab1e308e90", "metadata": {"tags": []}, "outputs": [], "source": "sorted_customers_df=customers_df.sortWithinPartitions('customer_id')\nsorted_orders_df=full_orders_df.sortWithinPartitions('customer_id')\noptimized_merge_full_orders_df=sorted_orders_df.join(sorted_customers_df,'customer_id')"}, {"cell_type": "code", "execution_count": 12, "id": "2372c8fd-3354-4c09-aaff-de651a63f40e", "metadata": {"tags": []}, "outputs": [], "source": "## Buckets Join"}, {"cell_type": "code", "execution_count": 13, "id": "d3780860-4c20-48d2-969b-6a0528275a65", "metadata": {"tags": []}, "outputs": [], "source": "bucketed_customers_df=customers_df.repartition(10,'customer_id')\nbucketed_orders_df=full_orders_df.repartition(10,'customer_id')\nbucket_join_df= bucketed_orders_df.join(bucketed_customers_df,'customer_id')"}, {"cell_type": "code", "execution_count": 14, "id": "88b97d41-be75-44ea-950a-be8d83bfed8b", "metadata": {"tags": []}, "outputs": [], "source": "## Skew join Handling"}, {"cell_type": "code", "execution_count": 15, "id": "e2ce73c2-27a6-4f16-9134-1f8a113ea061", "metadata": {"tags": []}, "outputs": [], "source": "skew_handled_join=full_orders_df.join(customers_df,'customer_id')"}, {"cell_type": "code", "execution_count": null, "id": "b80baa2b-e8cc-4546-a7f3-c614f3ebf3a5", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.8"}}, "nbformat": 4, "nbformat_minor": 5}